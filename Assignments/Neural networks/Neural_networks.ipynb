{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "               xbox          ybox         width       height         onpix  \\\n",
      "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
      "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
      "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
      "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
      "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
      "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
      "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
      "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
      "\n",
      "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
      "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
      "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
      "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
      "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
      "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
      "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
      "\n",
      "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
      "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
      "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
      "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
      "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
      "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
      "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
      "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
      "\n",
      "            yedgex  \n",
      "count  20000.00000  \n",
      "mean       7.80120  \n",
      "std        1.61747  \n",
      "min        0.00000  \n",
      "25%        7.00000  \n",
      "50%        8.00000  \n",
      "75%        9.00000  \n",
      "max       15.00000  \n",
      "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
      "0      T     2     8      3       5      1     8    13      0      6      6   \n",
      "1      I     5    12      3       7      2    10     5      5      4     13   \n",
      "2      D     4    11      6       8      6    10     6      2      6     10   \n",
      "3      N     7    11      6       6      3     5     9      4      6      4   \n",
      "4      G     2     1      3       1      1     8     6      6      6      6   \n",
      "\n",
      "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
      "0      10       8      0       8      0       8  \n",
      "1       3       9      2       8      4      10  \n",
      "2       3       7      3       7      3       9  \n",
      "3       4      10      6      10      2       8  \n",
      "4       5       9      1       7      5      10  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Alphabets_data.csv')\n",
    "\n",
    "# Explore basic information about the dataset\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Splitting features and target\n",
    "X = df.drop('letter', axis=1)  # assuming 'target' is the column with class labels\n",
    "y = df['letter']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the training target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Optionally, apply the transformation to the test set as well\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(26, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 16000\n",
      "4000 4000\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape[0], y_train.shape[0])  # Should be equal\n",
    "print(X_test_scaled.shape[0], y_test.shape[0])    # Should be equal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 16)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)  # Should be (num_samples, num_features)\n",
    "print(y_train_encoded.shape)         # Should be (num_samples,) for regression or (num_samples, num_classes) for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_scaled)) \n",
    "\n",
    "\n",
    "print(type(y_train_encoded))         # Should be <class 'numpy.ndarray'> or a Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2155 - loss: 3.0223 - val_accuracy: 0.4613 - val_loss: 2.1668\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5122 - loss: 1.9941 - val_accuracy: 0.5922 - val_loss: 1.6282\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6111 - loss: 1.5552 - val_accuracy: 0.6352 - val_loss: 1.4006\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6471 - loss: 1.3594 - val_accuracy: 0.6773 - val_loss: 1.2603\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6789 - loss: 1.2285 - val_accuracy: 0.7038 - val_loss: 1.1774\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6955 - loss: 1.1631 - val_accuracy: 0.7130 - val_loss: 1.1147\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7164 - loss: 1.0868 - val_accuracy: 0.7360 - val_loss: 1.0571\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7235 - loss: 1.0474 - val_accuracy: 0.7310 - val_loss: 1.0280\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7386 - loss: 1.0076 - val_accuracy: 0.7390 - val_loss: 0.9857\n",
      "Epoch 10/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7436 - loss: 0.9798 - val_accuracy: 0.7590 - val_loss: 0.9598\n",
      "Epoch 11/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7543 - loss: 0.9415 - val_accuracy: 0.7645 - val_loss: 0.9277\n",
      "Epoch 12/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7520 - loss: 0.9290 - val_accuracy: 0.7713 - val_loss: 0.9126\n",
      "Epoch 13/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7565 - loss: 0.9187 - val_accuracy: 0.7688 - val_loss: 0.9029\n",
      "Epoch 14/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7664 - loss: 0.8899 - val_accuracy: 0.7747 - val_loss: 0.8765\n",
      "Epoch 15/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7716 - loss: 0.8686 - val_accuracy: 0.7782 - val_loss: 0.8610\n",
      "Epoch 16/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7672 - loss: 0.8786 - val_accuracy: 0.7850 - val_loss: 0.8373\n",
      "Epoch 17/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7731 - loss: 0.8521 - val_accuracy: 0.7855 - val_loss: 0.8326\n",
      "Epoch 18/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7794 - loss: 0.8250 - val_accuracy: 0.7872 - val_loss: 0.8130\n",
      "Epoch 19/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7773 - loss: 0.8283 - val_accuracy: 0.7878 - val_loss: 0.8023\n",
      "Epoch 20/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7807 - loss: 0.8047 - val_accuracy: 0.7875 - val_loss: 0.7887\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test_scaled, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 15s]\n",
      "val_accuracy: 0.6585000157356262\n",
      "\n",
      "Best val_accuracy So Far: 0.812749981880188\n",
      "Total elapsed time: 00h 01m 26s\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "# Define the model building function for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('units', min_value=32, max_value=256, step=32), activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "    model.add(Dense(26, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Float('lr', min_value=1e-5, max_value=1e-2, sampling='log')), \n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.RandomSearch(build_model, objective='val_accuracy', max_trials=5, executions_per_trial=1, directory='output')\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train_scaled, y_train_encoded, epochs=20, validation_data=(X_test_scaled, y_test_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step\n",
      "Accuracy: 0.7875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       149\n",
      "           1       0.61      0.84      0.71       153\n",
      "           2       0.70      0.72      0.71       137\n",
      "           3       0.63      0.86      0.73       156\n",
      "           4       0.73      0.91      0.81       141\n",
      "           5       0.74      0.82      0.78       140\n",
      "           6       0.73      0.46      0.57       160\n",
      "           7       0.69      0.58      0.63       144\n",
      "           8       0.91      0.80      0.85       146\n",
      "           9       0.81      0.86      0.83       149\n",
      "          10       0.67      0.72      0.69       130\n",
      "          11       0.87      0.83      0.85       155\n",
      "          12       0.90      0.92      0.91       168\n",
      "          13       0.91      0.82      0.86       151\n",
      "          14       0.72      0.81      0.76       145\n",
      "          15       0.94      0.77      0.85       173\n",
      "          16       0.76      0.71      0.73       166\n",
      "          17       0.69      0.79      0.73       160\n",
      "          18       0.70      0.51      0.59       171\n",
      "          19       0.83      0.82      0.82       163\n",
      "          20       0.89      0.86      0.88       183\n",
      "          21       0.91      0.89      0.90       158\n",
      "          22       0.88      0.93      0.90       148\n",
      "          23       0.87      0.79      0.83       154\n",
      "          24       0.82      0.79      0.81       168\n",
      "          25       0.79      0.78      0.78       132\n",
      "\n",
      "    accuracy                           0.79      4000\n",
      "   macro avg       0.79      0.79      0.79      4000\n",
      "weighted avg       0.79      0.79      0.79      4000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[133   0   0   2   0   0   0   0   0   4   3   0   0   0   1   0   0   2\n",
      "    1   0   1   0   0   1   1   0]\n",
      " [  0 129   0   7   0   0   0   6   0   0   0   0   0   0   2   2   1   5\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  0   0  98   3   4   1   4   1   0   0  12   0   0   0   4   0   1   0\n",
      "    3   1   4   1   0   0   0   0]\n",
      " [  2   6   0 134   0   1   0   1   0   2   1   0   1   3   1   1   0   1\n",
      "    0   1   0   0   0   1   0   0]\n",
      " [  0   2   0   0 128   0   2   0   0   0   2   0   0   0   0   0   4   1\n",
      "    1   1   0   0   0   0   0   0]\n",
      " [  0   8   1   1   1 115   3   1   0   1   0   0   0   0   0   0   0   4\n",
      "    1   3   0   0   1   0   0   0]\n",
      " [  1   5  39   1   2   0  74   2   0   0   4   3   1   0   1   0  14   4\n",
      "    4   0   0   2   3   0   0   0]\n",
      " [  1   5   0  16   0   2   0  84   0   2   6   0   2   3   3   1   2  13\n",
      "    0   0   2   0   0   0   2   0]\n",
      " [  0   1   0   3   1   2   0   0 117   8   0   2   0   0   0   1   0   0\n",
      "    5   0   0   0   0   4   2   0]\n",
      " [  1   2   0   2   0   3   0   0   6 128   0   0   0   0   1   1   0   0\n",
      "    3   0   0   0   0   2   0   0]\n",
      " [  0   0   3   4   5   0   0   3   0   0  93   1   0   0   0   0   0  13\n",
      "    0   0   3   1   0   4   0   0]\n",
      " [  0   1   0   1  10   0   4   0   0   0   1 128   0   1   1   0   4   0\n",
      "    2   0   0   0   0   2   0   0]\n",
      " [  2   2   0   0   0   0   0   0   0   0   0   0 154   3   0   0   0   2\n",
      "    0   0   1   0   4   0   0   0]\n",
      " [  0   0   0   5   0   0   0   3   0   0   6   0   1 124   6   0   0   2\n",
      "    0   1   1   0   2   0   0   0]\n",
      " [  2   0   0  10   0   0   0   2   0   1   0   0   2   0 117   0   2   2\n",
      "    0   0   2   0   5   0   0   0]\n",
      " [  0   2   0   1   0  19   7   0   1   0   0   0   0   0   3 134   0   0\n",
      "    0   1   0   0   0   0   5   0]\n",
      " [  4  11   0   1   6   0   2   2   0   1   0   1   0   0   8   0 118   0\n",
      "    2   0   0   3   1   0   4   2]\n",
      " [  1  13   0   6   1   0   1   6   0   0   3   0   0   0   0   0   0 126\n",
      "    0   1   0   0   0   2   0   0]\n",
      " [  0  18   0   3   5   3   0   1   2   2   0  10   0   0   2   1   1   4\n",
      "   88   2   0   0   0   1   7  21]\n",
      " [  0   2   0   2   2   5   3   3   0   0   2   0   0   0   0   0   0   1\n",
      "    2 133   1   0   0   0   3   4]\n",
      " [  0   0   0   1   0   0   0   1   0   0   1   0   8   2  10   0   0   1\n",
      "    0   0 158   0   1   0   0   0]\n",
      " [  1   3   0   0   0   0   1   3   0   0   0   0   1   0   1   1   0   1\n",
      "    0   0   1 141   2   0   2   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   2   0   2   0   0   0\n",
      "    0   0   3   2 138   0   0   0]\n",
      " [  0   1   0   6   4   0   0   0   2   0   4   1   0   0   0   0   7   0\n",
      "    2   1   1   0   0 122   2   1]\n",
      " [  2   0   0   3   0   5   0   1   0   0   0   0   0   0   0   0   2   0\n",
      "    1  15   0   5   0   1 133   0]\n",
      " [  0   0   0   0   6   0   0   0   0   9   0   1   0   0   0   0   0   1\n",
      "   11   1   0   0   0   0   0 103]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the default model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "print('Accuracy:', accuracy_score(y_test_encoded, y_pred_classes))\n",
    "print('Classification Report:\\n', classification_report(y_test_encoded, y_pred_classes))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test_encoded, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │         \u001b[38;5;34m1,690\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,778</span> (10.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,778\u001b[0m (10.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,778</span> (10.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,778\u001b[0m (10.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       149\n",
      "           1       0.00      0.00      0.00       153\n",
      "           2       0.09      0.98      0.17       137\n",
      "           3       0.00      0.00      0.00       156\n",
      "           4       0.11      0.91      0.19       141\n",
      "           5       0.43      0.62      0.51       140\n",
      "           6       0.00      0.00      0.00       160\n",
      "           7       0.43      0.26      0.32       144\n",
      "           8       0.00      0.00      0.00       146\n",
      "           9       0.82      0.59      0.69       149\n",
      "          10       0.00      0.00      0.00       130\n",
      "          11       0.00      0.00      0.00       155\n",
      "          12       0.95      0.84      0.89       168\n",
      "          13       1.00      0.01      0.01       151\n",
      "          14       0.24      0.04      0.07       145\n",
      "          15       0.99      0.42      0.59       173\n",
      "          16       0.00      0.00      0.00       166\n",
      "          17       1.00      0.01      0.01       160\n",
      "          18       0.00      0.00      0.00       171\n",
      "          19       0.68      0.75      0.71       163\n",
      "          20       0.90      0.20      0.33       183\n",
      "          21       0.95      0.46      0.62       158\n",
      "          22       0.90      0.82      0.86       148\n",
      "          23       0.00      0.00      0.00       154\n",
      "          24       0.82      0.67      0.74       168\n",
      "          25       0.61      0.26      0.36       132\n",
      "\n",
      "    accuracy                           0.30      4000\n",
      "   macro avg       0.42      0.30      0.27      4000\n",
      "weighted avg       0.43      0.30      0.28      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test_encoded, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step\n",
      "Default Model Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       149\n",
      "           1       0.34      0.07      0.11       153\n",
      "           2       0.12      0.98      0.21       137\n",
      "           3       0.97      0.22      0.36       156\n",
      "           4       0.14      0.94      0.24       141\n",
      "           5       0.47      0.63      0.54       140\n",
      "           6       0.00      0.00      0.00       160\n",
      "           7       0.39      0.28      0.33       144\n",
      "           8       1.00      0.11      0.20       146\n",
      "           9       0.87      0.64      0.74       149\n",
      "          10       0.12      0.02      0.03       130\n",
      "          11       0.00      0.00      0.00       155\n",
      "          12       0.95      0.84      0.89       168\n",
      "          13       1.00      0.02      0.04       151\n",
      "          14       0.47      0.13      0.21       145\n",
      "          15       1.00      0.34      0.50       173\n",
      "          16       0.24      0.12      0.16       166\n",
      "          17       0.76      0.08      0.15       160\n",
      "          18       0.33      0.02      0.03       171\n",
      "          19       0.58      0.85      0.69       163\n",
      "          20       0.56      0.44      0.49       183\n",
      "          21       0.69      0.79      0.74       158\n",
      "          22       0.90      0.68      0.77       148\n",
      "          23       0.00      0.00      0.00       154\n",
      "          24       0.78      0.83      0.80       168\n",
      "          25       0.52      0.71      0.60       132\n",
      "\n",
      "    accuracy                           0.37      4000\n",
      "   macro avg       0.51      0.37      0.34      4000\n",
      "weighted avg       0.52      0.37      0.34      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate default model\n",
    "default_model = model\n",
    "y_pred_default = default_model.predict(X_test)\n",
    "y_pred_classes_default = y_pred_default.argmax(axis=1)\n",
    "print(\"Default Model Performance:\\n\", classification_report(y_test_encoded, y_pred_classes_default))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Insights:\n",
    "\n",
    "Low Precision and Recall for Many Classes:\n",
    "\n",
    "Precision, recall, and f1-scores are low for many of the classes (especially class 0, 6, 11, 13, and 18).\n",
    "\n",
    "For instance, for class 0, the precision and recall are 0.00, which indicates that the model is not predicting this class at all, and even when it does, the predictions are incorrect.\n",
    "\n",
    "For class 2, the recall is high (0.98), meaning the model is good at identifying this class, but its precision is still low (0.12), suggesting many false positives.\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "The overall accuracy is 37%, which indicates that the model is not doing well in correctly classifying the data across all classes.\n",
    "The accuracy alone isn't enough to determine the model's performance, especially in a multiclass classification problem, where a more detailed analysis using precision, recall, and f1-scores is necessary.\n",
    "\n",
    "Imbalanced Classes:\n",
    "\n",
    "The classes have varying numbers of instances (support column), which suggests that the dataset might be imbalanced. Some classes have significantly more samples (e.g., class 19 has 163 instances) while others have fewer (e.g., class 0 has 149 instances).\n",
    "\n",
    "This class imbalance can lead to poor model performance, especially when the model is biased towards predicting the more frequent classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
