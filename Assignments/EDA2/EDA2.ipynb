{"cells":[{"cell_type":"markdown","metadata":{},"source":["**1. Data Exploration and Preprocessing**\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   age          workclass  fnlwgt   education  education_num  \\\n","0   39          State-gov   77516   Bachelors             13   \n","1   50   Self-emp-not-inc   83311   Bachelors             13   \n","2   38            Private  215646     HS-grad              9   \n","3   53            Private  234721        11th              7   \n","4   28            Private  338409   Bachelors             13   \n","\n","        marital_status          occupation    relationship    race      sex  \\\n","0        Never-married        Adm-clerical   Not-in-family   White     Male   \n","1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n","2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n","3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n","4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n","\n","   capital_gain  capital_loss  hours_per_week  native_country  income  \n","0          2174             0              40   United-States   <=50K  \n","1             0             0              13   United-States   <=50K  \n","2             0             0              40   United-States   <=50K  \n","3             0             0              40   United-States   <=50K  \n","4             0             0              40            Cuba   <=50K  \n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 32561 entries, 0 to 32560\n","Data columns (total 15 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   age             32561 non-null  int64 \n"," 1   workclass       32561 non-null  object\n"," 2   fnlwgt          32561 non-null  int64 \n"," 3   education       32561 non-null  object\n"," 4   education_num   32561 non-null  int64 \n"," 5   marital_status  32561 non-null  object\n"," 6   occupation      32561 non-null  object\n"," 7   relationship    32561 non-null  object\n"," 8   race            32561 non-null  object\n"," 9   sex             32561 non-null  object\n"," 10  capital_gain    32561 non-null  int64 \n"," 11  capital_loss    32561 non-null  int64 \n"," 12  hours_per_week  32561 non-null  int64 \n"," 13  native_country  32561 non-null  object\n"," 14  income          32561 non-null  object\n","dtypes: int64(6), object(9)\n","memory usage: 3.7+ MB\n","None\n","                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n","count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n","mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n","std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n","min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n","25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n","50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n","75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n","max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n","\n","       hours_per_week  \n","count    32561.000000  \n","mean        40.437456  \n","std         12.347429  \n","min          1.000000  \n","25%         40.000000  \n","50%         40.000000  \n","75%         45.000000  \n","max         99.000000  \n"]},{"ename":"TypeError","evalue":"'Series' object is not callable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[40], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39minfo())\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[1;31mTypeError\u001b[0m: 'Series' object is not callable"]}],"source":["import pandas as pd\n","\n","# Load the dataset\n","data = pd.read_csv('adult_with_headers.csv')\n","\n","# Show basic information\n","print(data.head())\n","print(data.info())\n","print(data.describe())\n","print(data.dtypes())"]},{"cell_type":"markdown","metadata":{},"source":["**2: Handle Missing Values**"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["age               0\n","workclass         0\n","fnlwgt            0\n","education         0\n","education_num     0\n","marital_status    0\n","occupation        0\n","relationship      0\n","race              0\n","sex               0\n","capital_gain      0\n","capital_loss      0\n","hours_per_week    0\n","native_country    0\n","income            0\n","dtype: int64\n"]}],"source":["# Check for missing values\n","print(data.isnull().sum())\n","\n","# Imputation or removal based on analysis\n","data = data.dropna()  # or fill with mean, mode, median as needed\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["            age    fnlwgt  education_num  capital_gain  capital_loss  \\\n","0      0.301370  0.044302       0.800000      0.021740           0.0   \n","1      0.452055  0.048238       0.800000      0.000000           0.0   \n","2      0.287671  0.138113       0.533333      0.000000           0.0   \n","3      0.493151  0.151068       0.400000      0.000000           0.0   \n","4      0.150685  0.221488       0.800000      0.000000           0.0   \n","...         ...       ...            ...           ...           ...   \n","32556  0.136986  0.166404       0.733333      0.000000           0.0   \n","32557  0.315068  0.096500       0.533333      0.000000           0.0   \n","32558  0.561644  0.094827       0.533333      0.000000           0.0   \n","32559  0.068493  0.128499       0.533333      0.000000           0.0   \n","32560  0.479452  0.187203       0.533333      0.150242           0.0   \n","\n","       hours_per_week  \n","0            0.397959  \n","1            0.122449  \n","2            0.397959  \n","3            0.397959  \n","4            0.397959  \n","...               ...  \n","32556        0.377551  \n","32557        0.397959  \n","32558        0.397959  \n","32559        0.193878  \n","32560        0.397959  \n","\n","[30933 rows x 6 columns]\n"]},{"ename":"ValueError","evalue":"No objects to concatenate","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[39], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[numerical_features])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Encode categorical variables\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Apply One-Hot Encoding for categorical variables with <5 categories, Label Encoding otherwise\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m df_encoded\u001b[38;5;241m.\u001b[39mdescribe()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\reshape\\encoding.py:219\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    209\u001b[0m         dummy \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    210\u001b[0m             col[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    211\u001b[0m             prefix\u001b[38;5;241m=\u001b[39mpre,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    217\u001b[0m         )\n\u001b[0;32m    218\u001b[0m         with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[1;32m--> 219\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_dummies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     result \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    222\u001b[0m         data,\n\u001b[0;32m    223\u001b[0m         prefix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    229\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\reshape\\concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n","\u001b[1;31mValueError\u001b[0m: No objects to concatenate"]}],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n","\n","# Separate numerical and categorical columns\n","numerical_features = data.select_dtypes(include=['int64', 'float64']).columns\n","categorical_features = data.select_dtypes(include=['object']).columns\n","print(data[numerical_features])\n","# Encode categorical variables\n","# Apply One-Hot Encoding for categorical variables with <5 categories, Label Encoding otherwise\n","df_encoded = pd.get_dummies(data[categorical_features], drop_first=True)\n","df_encoded.describe()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**3: Apply Scaling Techniques**"]},{"cell_type":"markdown","metadata":{},"source":["Standard Scaling (Z-score normalization): This scales data such that the mean becomes 0 and standard deviation becomes 1."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","data[['age', 'hours_per_week']] = scaler.fit_transform(data[['age', 'hours_per_week']])\n"]},{"cell_type":"markdown","metadata":{},"source":["Min-Max Scaling"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","min_max_scaler = MinMaxScaler()\n","data[['age', 'hours_per_week']] = min_max_scaler.fit_transform(data[['age', 'hours_per_week']])\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","# Select only numerical columns for scaling\n","numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n","\n","# # Apply Standard Scaling or Min-Max Scaling to numerical columns only\n","# scaler = StandardScaler()\n","# data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n","\n","# Alternatively, for Min-Max Scaling:\n","min_max_scaler = MinMaxScaler()\n","data[numerical_cols] = min_max_scaler.fit_transform(data[numerical_cols])\n"]},{"cell_type":"markdown","metadata":{},"source":["Discussion:\n","\n","Standard Scaling is preferred when features have different units or ranges, or for algorithms that rely on the assumption of normally distributed features (like linear regression).\n","\n","Min-Max Scaling is preferred when the data needs to be within a fixed range, for example in neural networks where bounded input can lead to faster convergence."]},{"cell_type":"markdown","metadata":{},"source":["**Encoding Techniques**"]},{"cell_type":"markdown","metadata":{},"source":["One-Hot Encoding (for categorical variables with less than 5 categories):"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Apply one-hot encoding\n","data = pd.get_dummies(data, columns=['sex', 'marital_status'], drop_first=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["Label Encoding (for categorical variables with more than 5 categories):\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Apply label encoding\n","le = LabelEncoder()\n","data['occupation'] = le.fit_transform(data['occupation'])\n"]},{"cell_type":"markdown","metadata":{},"source":["Discussion:\n","\n","One-Hot Encoding Pros: Works well for non-ordinal categorical features. Helps machine learning algorithms to interpret categorical features correctly.\n","\n","One-Hot Encoding Cons: May lead to a large number of features if there are many categories.\n","\n","Label Encoding Pros: Efficient for high-cardinality features and does not increase dimensionality.\n","\n","Label Encoding Cons: Assumes an order between labels, which may mislead some models (e.g., tree-based methods)."]},{"cell_type":"markdown","metadata":{},"source":["**Feature Engineering**"]},{"cell_type":"markdown","metadata":{},"source":["New Features:\n","\n","Work-Life Balance Feature: Ratio of hours worked per week to age.\n","\n","Capital Change Feature: Difference between capital gains and losses."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import numpy as np\n","data['capital_change'] = data['capital_gain'] - data['capital_loss']\n","\n","data['capital_gain_log'] = np.log1p(data['capital_gain'])\n"]},{"cell_type":"markdown","metadata":{},"source":["**Feature Selection**"]},{"cell_type":"markdown","metadata":{},"source":["Isolation Forest for Outlier Detection:"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import IsolationForest\n","\n","# Initialize Isolation Forest model\n","iso_forest = IsolationForest(contamination=0.05)  # Assume 5% contamination\n","outliers = iso_forest.fit_predict(data.select_dtypes(include=['float64', 'int64']))\n","\n","# Filter out outliers\n","data = data[outliers == 1]\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**Predictive Power Score (PPS):**"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'ppscore'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Install the PPS library if not already installed\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# !pip install ppscore\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mppscore\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpps\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate PPS matrix for entire dataset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m pps_matrix \u001b[38;5;241m=\u001b[39m pps\u001b[38;5;241m.\u001b[39mmatrix(data)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ppscore'"]}],"source":["# Install the PPS library if not already installed\n","# !pip install ppscore\n","\n","import ppscore as pps\n","\n","# Calculate PPS matrix for entire dataset\n","pps_matrix = pps.matrix(data)\n","print(pps_matrix[['x', 'y', 'ppscore']].sort_values(by='ppscore', ascending=False).head(10))\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                     age    fnlwgt  education_num  capital_gain  capital_loss  \\\n","age             1.000000 -0.076646       0.036527      0.077674      0.057775   \n","fnlwgt         -0.076646  1.000000      -0.043195      0.000432     -0.010252   \n","education_num   0.036527 -0.043195       1.000000      0.122630      0.079923   \n","capital_gain    0.077674  0.000432       0.122630      1.000000     -0.031615   \n","capital_loss    0.057775 -0.010252       0.079923     -0.031615      1.000000   \n","hours_per_week  0.068756 -0.018768       0.148123      0.078409      0.054256   \n","\n","                hours_per_week  \n","age                   0.068756  \n","fnlwgt               -0.018768  \n","education_num         0.148123  \n","capital_gain          0.078409  \n","capital_loss          0.054256  \n","hours_per_week        1.000000  \n"]}],"source":["datanew=data.drop(columns=['workclass','education'])\n","correlation_matrix = datanew.corr(numeric_only=True)\n","print(correlation_matrix)\n"]},{"cell_type":"markdown","metadata":{},"source":["**Observations:**\n","\n","Age: Has weak positive correlations with most features, including a 0.068 correlation with hours_per_week. This indicates that older people tend to work slightly more hours, although the relationship is weak.\n","\n","Fnlwgt (final weight): Shows weak correlations with all features, suggesting it has little linear relationship with other variables.\n","\n","Education_num: Shows a moderate positive correlation with hours_per_week (0.148) and a weaker positive relationship with capital_gain (0.122), suggesting that higher education may have some association with working more hours and earning more in capital gains.\n","\n","Capital_gain and Capital_loss: Have very weak correlations with other features. Notably, capital_gain has a slightly positive relationship with education_num.\n","\n","Hours_per_week: Has the strongest positive linear relationship with education_num (0.148), indicating that higher education levels may be associated with working more hours."]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
